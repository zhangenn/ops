{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Column, Integer, String, DateTime\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used full file path for testing purpose\n",
    "json_file = pd.read_json(\"/Users/EmilyWang/Desktop/ops/paper-collector/DeepLearningArticles.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information\n",
    "json_file['published_date'] = json_file['published'].str.extract('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', expand=True)\n",
    "json_file['published_time'] = json_file['published'].str.extract('(\\d\\d:\\d\\d:\\d\\d)', expand=True)\n",
    "json_file['updated_date'] = json_file['updated'].str.extract('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', expand=True)\n",
    "json_file['updated_time'] = json_file['updated'].str.extract('(\\d\\d:\\d\\d:\\d\\d)', expand=True)\n",
    "json_file['unique_id'] = json_file['id'].str.extract('(\\d\\d\\d\\d\\.\\d\\d\\d\\d\\d)', expand=True)\n",
    "json_file['version_number'] = json_file['id'].str.extract('(\\d$)', expand=True)\n",
    "\n",
    "final_json = json_file[['unique_id', 'version_number', 'author', \n",
    "                        'title', 'summary', 'arxiv_comment', \n",
    "                        'published_date', 'published_time', \n",
    "                        'updated_date', 'updated_time']]\n",
    "\n",
    "final_json = final_json.drop_duplicates(subset='unique_id', keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local db url\n",
    "db_url = {'drivername': 'postgres',\n",
    "          'username': 'postgres',\n",
    "          'password': 'postgres',\n",
    "          'host': '127.0.0.1',\n",
    "          'port': 5432}\n",
    "engine = create_engine(URL(**db_url))\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTable(Base):\n",
    "    __tablename__ = 'Test Table'\n",
    "    id = Column(String, primary_key=True)\n",
    "    version = Column(Integer, nullable=False)\n",
    "    author = Column(String, nullable=False)\n",
    "    title = Column(String, nullable=False)\n",
    "    summary = Column(String)\n",
    "    arxiv_comment = Column(String)\n",
    "    published_date = Column(String)\n",
    "    published_time = Column(String)\n",
    "    updated_date = Column(String)\n",
    "    updated_time = Column(String)\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
    "\n",
    "# create tables\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\n",
    "# create session\n",
    "Session = sessionmaker()\n",
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = final_json.to_dict('records')\n",
    "\n",
    "for i in range(len(json_dict)):\n",
    "    row = TestTable(id = json_dict[i]['unique_id'], \n",
    "                    version = json_dict[i]['version_number'], \n",
    "                    author = json_dict[i]['author'], \n",
    "                    title = json_dict[i]['title'], \n",
    "                    summary = json_dict[i]['summary'], \n",
    "                    arxiv_comment = json_dict[i]['arxiv_comment'], \n",
    "                    published_date = json_dict[i]['published_date'], \n",
    "                    published_time = json_dict[i]['published_time'], \n",
    "                    updated_date = json_dict[i]['updated_date'], \n",
    "                    updated_time = json_dict[i]['updated_time'])\n",
    "    session.add(row)\n",
    "    \n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1903.05696', 2, 'Aaron Hertzmann', 'Aesthetics of Neural Network Art', 'This paper proposes a way to understand neural network artworks as\\njuxtapositions of natural image cues. It is hypothesized that images with\\nunusua ... (270 characters truncated) ... ariations. This analysis is applied to\\nneural art based on Generative Adversarial Networks, image stylization, Deep\\nDreams, and Perception Engines.', None, '2019-03-13', '19:45:54', '2019-03-18', '17:58:15', datetime.datetime(2019, 3, 20, 1, 44, 37, 106419))\n",
      "('1712.05474', 3, 'Ali Farhadi', 'AI2-THOR: An Interactive 3D Environment for Visual AI', 'We introduce The House Of inteRactions (THOR), a framework for visual AI\\nresearch, available at http://ai2thor.allenai.org. AI2-THOR consists of nea ... (401 characters truncated) ... rning models of cognition. The goal of AI2-THOR is to\\nfacilitate building visually intelligent models and push the research forward\\nin this domain.', None, '2017-12-14', '23:17:24', '2019-03-15', '18:29:15', datetime.datetime(2019, 3, 20, 1, 44, 37, 106428))\n",
      "('1903.06549', 1, 'Kazuhiro Fukui', 'Constrained Mutual Convex Cone Method for Image Set Based Recognition', 'In this paper, we propose a method for image-set classification based on\\nconvex cone models. Image set classification aims to classify a set of imag ... (1190 characters truncated) ... g five databases: CMU PIE dataset, ETH-80,\\nCMU Motion of Body dataset, Youtube Celebrity dataset, and a private database\\nof multi-view hand shapes.', 'arXiv admin note: substantial text overlap with arXiv:1805.12467', '2019-03-14', '07:14:34', '2019-03-14', '07:14:34', datetime.datetime(2019, 3, 20, 1, 44, 37, 106431))\n",
      "('1903.06187', 1, 'Ambuj Tewari', 'Contextual Markov Decision Processes using Generalized Linear Models', 'We consider the recently proposed reinforcement learning (RL) framework of\\nContextual Markov Decision Processes (CMDP), where the agent has a sequen ... (691 characters truncated) ... ce sets. Moreover, for\\nany strongly convex link function, we also show a generic conversion from any\\nonline no-regret algorithm to confidence sets.', 'In submission', '2019-03-14', '18:02:09', '2019-03-14', '18:02:09', datetime.datetime(2019, 3, 20, 1, 44, 37, 106434))\n",
      "('1806.06439', 2, 'James Robinson', 'Predicting Switching Graph Labelings with Cluster Specialists', 'We address the problem of predicting the labeling of a graph in an online\\nsetting when the labeling is changing over time. Our primary algorithm is  ... (664 characters truncated) ... formance of these algorithms against an existing\\nalgorithm (a kernelized Perceptron) and show that our algorithms perform better\\non synthetic data.', \"Updated version: Refined analysis of primary algorithm to give\\n  'smooth' bounds. Perceptron material now appears in the appendix\", '2018-06-17', '20:17:33', '2019-03-14', '18:21:05', datetime.datetime(2019, 3, 20, 1, 44, 37, 106436))\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "result = engine.execute('SELECT * FROM '\n",
    "                        '\"Test Table\" LIMIT 5')\n",
    "for _r in result:\n",
    "   print(_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
